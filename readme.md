## Groq-Powered Chat Model using LangChain + Streamlit

This project is a lightweight, high-performance LLM chat interface built with:

`Groq API` (ultra-fast inference)

`LangChain` (prompt handling & chat orchestration)
Gradio (frontend UI)

`Python backend`
It provides a clean and responsive interface to interact with LLMs served through Groq, packaged as a simple and extensible app.

### âœ¨ Features
âš¡ Groq Chat Completion with lightning-fast responses
ğŸ§  LangChain integration for prompt/response handling
ğŸŒ Gradio web UI for clean and interactive chat
ğŸ” Environment-variable-based secrets (no hard-coded API keys)

ğŸ“¦ Fully portable â€” deploy on Cloud, HuggingFace Spaces, or locally

ğŸ§© Modular architecture â€” easily extend with new models or chains

- ğŸ“ Project Structure
```
chat_model/
â”œâ”€â”€ Chat_Model.py     
â”œâ”€â”€ .env(git)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md